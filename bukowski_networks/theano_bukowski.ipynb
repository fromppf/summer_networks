{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano Neural Network on Bukowski\n",
    "On this notebook I improve the [Numpy Bukowski](https://github.com/masta-g3/summer_networks/tree/master/numpy_bukowski) poetry model by porting the code to Theano, which should perform much faster. Since the preprocessing section remains exactly the same, I start by loading the previously formatted dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries.\n",
    "import itertools\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = 10000\n",
    "unknown_token = 'UNKNOWN_TOKEN'\n",
    "start_symbol = 'START_SYMBOL'\n",
    "stop_symbol = 'STOP_SYMBOL'\n",
    "\n",
    "content = pd.read_pickle('data/content.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16271 unique words tokens.\n"
     ]
    }
   ],
   "source": [
    "## Get word frequency.\n",
    "sentences = [content.loc[i, 'tokens'] for i in content.index]\n",
    "flattened = itertools.chain.from_iterable(sentences) \n",
    "word_freq = nltk.FreqDist(flattened)\n",
    "print 'Found %d unique words tokens.' % len(word_freq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary size 10000.\n",
      "The least frequent word in our vocabulary is 'pandered' and appeared 1 times.\n"
     ]
    }
   ],
   "source": [
    "## Limit vocabulary to most common words.\n",
    "vocab = word_freq.most_common(size-1)\n",
    "word_list = [x[0] for x in vocab]\n",
    "word_list.append(unknown_token)\n",
    "word_list\n",
    "word_index = dict([(w,i) for i,w in enumerate(word_list)])\n",
    "\n",
    "print 'Using vocabulary size %d.' % size\n",
    "print \"The least frequent word in our vocabulary is '%s' (%d appearance).\" % (vocab[-1][0], vocab[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed poem:\n",
      "\n",
      "she wrote me a letter from a small\n",
      "room near the UNKNOWN_TOKEN .\n",
      "she said she was going to dancing\n",
      "class . she got up , she said\n",
      "at 5 o'clock in the morning\n",
      "and typed at poems\n",
      "or painted\n",
      "and when she felt like crying\n",
      "she had a special bench\n",
      "by the river .\n",
      "her book of UNKNOWN_TOKEN\n",
      "would be out\n",
      "in the fall .\n",
      "i did not know what to tell her\n",
      "but\n",
      "i told her\n",
      "to get any bad teeth pulled\n",
      "and be careful of the french\n",
      "lover .\n",
      "i put her photo by the radio\n",
      "near the fan\n",
      "and it moved\n",
      "like something\n",
      "alive .\n",
      "i sat and watched it\n",
      "until i had smoked the\n",
      "5 or 6\n",
      "cigarettes left .\n",
      "then i got up\n",
      "and went to bed .\n"
     ]
    }
   ],
   "source": [
    "## Replace words not in dictionary with the unknown token.\n",
    "for i, row in content.iterrows():\n",
    "    for j, tkn in enumerate(row['tokens']):\n",
    "        if tkn not in word_list:\n",
    "            content.loc[i, 'tokens'][j] = unknown_token\n",
    "            \n",
    "print 'Sample processed poem:\\n'\n",
    "for index, row in content[content['poem'] == 45].iterrows():\n",
    "    print ' '.join(row['tokens'][1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally our network will produce a text like the above ðŸ˜Š. Note that given the particular style of Bukowski, we are not interested in generating perfect grammatical or syntactical structure, and indeed this algorithm does not incorporate any type of CFG, dependency parsing or any other language-specific attributes. As long as the network produces sentences with a Bukowski feel, we will have achieved our goal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input data:  START_SYMBOL there is a UNKNOWN_TOKEN of some sort\n",
      "Example Output data: there is a UNKNOWN_TOKEN of some sort STOP_SYMBOL\n"
     ]
    }
   ],
   "source": [
    "## Convert the info into training data.\n",
    "X_train = np.asarray([[word_index[w] for w in sent[:-1]] for sent in content['tokens'].tolist()])\n",
    "y_train = np.asarray([[word_index[w] for w in sent[1:]] for sent in content['tokens'].tolist()])\n",
    "\n",
    "## Show an example.\n",
    "x_example, y_example = X_train[49], y_train[49]\n",
    "print 'Example Input data: ', \n",
    "input_sent = [word_list[i] for i in x_example]\n",
    "print ' '.join(x for x in input_sent)\n",
    "\n",
    "print 'Example Output data:', \n",
    "output_sent = [word_list[j] for j in y_example]\n",
    "print ' '.join(x for x in output_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network\n",
    "Now that we have the data in the desired format, we start building the neural network. Our **RNNNumpy** class is made up by the following functions:\n",
    "\n",
    "* *__init__* â†’ Initializes parameters based on the number of word dimensions, hidden dimensions and random values taken from the uniform distribution $ \\left[\\dfrac{-1}{\\sqrt{n}}, \\dfrac{1}{\\sqrt{n}}\\right] $ for (U, V & W).\n",
    "\n",
    "* *forward_propagation* â†’ Generates the word probabilities by unfolding the neural network. Uses $tanh$ activation function for the input layer and $softmax$ for the output one.\n",
    "\n",
    "* *predict* â†’ Returns estimated output (i.e. the word with the highest probability of occuring next) from the forward propagation estimates.\n",
    "\n",
    "* *calculate_loss* â†’ Cross-entropy loss from prediction, as defined by the function below.\n",
    "\n",
    "    $ L(y,o) = \\dfrac{-1}{N} \\sum y_n log(o_n)$\n",
    "\n",
    "  \n",
    "* *bptt* â†’ Back-propagation algorithm, used to estimate gradients and update parameters.\n",
    "\n",
    "* *sgd_step* â†’ SGD to calculate gradients and perform updates in one batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNTheano:\n",
    "    \n",
    "    def __init__(self, w_dim, h_dim=100, bptt_max=4):\n",
    "        \n",
    "        ## Set self parameters.\n",
    "        self.w_dim = w_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.bptt_max = bptt_max    \n",
    "        \n",
    "        ## Randomly initialize network parameters. Set to uniform between\n",
    "        ## [-1/n, 1/n], where 'n' is the size of incoming connections.\n",
    "        U = np.random.uniform(-np.sqrt(1./w_dim), np.sqrt(1./w_dim), (h_dim, w_dim))\n",
    "        V = np.random.uniform(-np.sqrt(1./h_dim), np.sqrt(1./h_dim), (w_dim, h_dim))\n",
    "        W = np.random.uniform(-np.sqrt(1./h_dim), np.sqrt(1./h_dim), (h_dim, h_dim))\n",
    "        \n",
    "        ## Assign to self as theano shared variables.\n",
    "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "        self.V = theano.shared(name='U', value=V.astype(theano.config.floatX))\n",
    "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "        \n",
    "        ## Build Model.\n",
    "        self.theano = {}\n",
    "        self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        \n",
    "        ## Define parameters.\n",
    "        x = T.ivector('x')\n",
    "        y = T.ivector('y')\n",
    "        U, V, W = self.U, self.V, self.W\n",
    "        \n",
    "        ## Forward propagation to perform at each step.\n",
    "        def fwd_step(x_t, s_t_prev, U, V, W):\n",
    "            s_t = T.tanh(U[:,x_t] + W.dot(s_t_prev))\n",
    "            o_t = T.nnet.softmax(V.dot(s_t))\n",
    "            ## Softmax returns a matrix, so we convert it into a vector.\n",
    "            return [o_t[0], s_t]\n",
    "        \n",
    "        ## Iterate over all observations\n",
    "        [o,s], updates = theano.scan(fwd_step,\n",
    "                                     sequences=x,\n",
    "                                     outputs_info=[None, dict(initial = T.zeros(self.h_dim))],\n",
    "                                     non_sequences=[U,V,W],\n",
    "                                     truncate_gradient=self.bptt_max,\n",
    "                                     strict=True)\n",
    "        \n",
    "        ## Prediction and loss.\n",
    "        predict = T.argmax(o, axis=1)\n",
    "        o_error = T.sum(T.nnet.categorical_crossentropy(o, y))\n",
    "        \n",
    "        ## Define gradients.\n",
    "        dU = T.grad(o_error, U)\n",
    "        dV = T.grad(o_error, V)\n",
    "        dW = T.grad(o_error, W)\n",
    "        \n",
    "        ## Convert graph into actual functions.\n",
    "        self.fwd_prop = theano.function([x], o)\n",
    "        self.predict = theano.function([x], predict)\n",
    "        self.ce_error = theano.function([x,y], o_error)\n",
    "        self.bptt = theano.function([x,y], [dU, dV, dW])\n",
    "    \n",
    "        ## SGD.\n",
    "        l_rate = T.scalar('l_rate')\n",
    "        self.sgd_step = theano.function([x,y,l_rate], [],\n",
    "                                        updates = [(U, U - l_rate * dU),\n",
    "                                                   (V, V - l_rate * dV),\n",
    "                                                   (W, W - l_rate * dW)])\n",
    "    \n",
    "    ## Total loss function...\n",
    "    def total_loss_function(self, X, Y):\n",
    "        return np.sum([self.ce_error(x, y) for x,y in zip(X,Y)])\n",
    "        \n",
    "    ## Loss by word dimension.\n",
    "    def loss_function(self, X, Y):\n",
    "        n = np.sum([len(y) for y in Y])\n",
    "        return self.total_loss_function(X, Y) / float(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_with_sgd(model, X_train, y_train, l_rate=0.005, epochs=100, evaluate_after=10):\n",
    "    ## List to keep track of losses.\n",
    "    losses = []\n",
    "    examples_seen = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if(epoch % evaluate_after == 0):\n",
    "            loss = model.loss_function(X_train, y_train)\n",
    "            losses.append((examples_seen, loss))\n",
    "            time = datetime.now().strftime('%H:%M:%S')\n",
    "            print '%s: Loss after num_examples=%d & epoch=%d: %f.' %(time, examples_seen, epoch, loss)\n",
    "            \n",
    "            ## Adjust learning rate if loss increases.\n",
    "            if(len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                l_rate = l_rate * 0.5\n",
    "                print 'Updating learning rate to %f.' %l_rate\n",
    "\n",
    "        ## For each training example...\n",
    "        for i in range(len(y_train)):\n",
    "            ## do one SGD step.\n",
    "            model.sgd_step(X_train[i], y_train[i], l_rate)\n",
    "            examples_seen += 1\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create model with theano.\n",
    "model = RNNTheano(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:19:48: Loss after num_examples=0 & epoch=0: 9.210206.\n",
      "Setting learning rate to 0.002500.\n",
      "Setting learning rate to 0.001250.\n",
      "09:23:29: Loss after num_examples=68615 & epoch=9: 5.133469.\n",
      "Setting learning rate to 0.000625.\n",
      "Setting learning rate to 0.000313.\n",
      "Setting learning rate to 0.000156.\n",
      "18:09:51: Loss after num_examples=137230 & epoch=19: 4.946352.\n",
      "Setting learning rate to 0.000078.\n",
      "Setting learning rate to 0.000039.\n",
      "Setting learning rate to 0.000019.\n",
      "08:31:16: Loss after num_examples=205845 & epoch=29: 4.872901.\n",
      "Setting learning rate to 0.000010.\n",
      "16:14:03: Loss after num_examples=274460 & epoch=39: 4.860681.\n",
      "09:58:14: Loss after num_examples=343075 & epoch=49: 4.853041.\n",
      "Setting learning rate to 0.000002.\n",
      "Setting learning rate to 0.000001.\n",
      "Setting learning rate to 0.000001.\n",
      "21:58:14: Loss after num_examples=411690 & epoch=59: 4.852545."
     ]
    }
   ],
   "source": [
    "## Verify that indeed the algorithm reduces the error over time.\n",
    "losses = train_with_sgd(model, X_train, y_train, l_rate=0.005, epochs=60, evaluate_after=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f983d144710>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAHrCAYAAAAJ7AMUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f983d0f5d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([l[1] for l in losses], 'go')\n",
    "plt.plot([l[1] for l in losses], 'g-')\n",
    "plt.axhline(np.log(size))\n",
    "plt.title('Random Prediction vs. Model Errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first the error rate improves dramatically when compared to the random prediction model, but with each iteration it becomes harder to reduce it further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "\n",
    "Since running this model takes a looong time to run, its a good idea to save the parameters so we can access it or continue training it later. The functions below do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_model(filepath, model):\n",
    "    U, V, W = model.U.get_value(), model.V.get_value(), model.W.get_value()\n",
    "    np.savez(filepath, U=U, V=V, W=W)\n",
    "    print \"Saved model at '%s'.\" % filepath\n",
    "    \n",
    "def load_model(filepath, model):\n",
    "    npzmodel = np.load(filepath)\n",
    "    U, V, W = npzmodel[\"U\"], npzmodel[\"V\"], npzmodel[\"W\"]\n",
    "    model.h_dim = U.shape[0]\n",
    "    model.w_dim = U.shape[1]\n",
    "    model.U.set_value(U)\n",
    "    model.V.set_value(V)\n",
    "    model.W.set_value(W)\n",
    "    print \"Loaded model parameters from %s.\" % (filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model at 'trained_model.npz.'\n"
     ]
    }
   ],
   "source": [
    "save_model('trained_model.npz', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Sentences\n",
    "We can use this generative model to create new sentences that have the highest probability of looking like Bukowski's. The longer we train the network, the better looking sentences the algorithm generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reputation uselessly?\n",
      "ostriches remain my arrival,\n",
      "cigarette as both something things\n",
      "you've am Orleans\n",
      "my pier and -which\n",
      "from the biggest 15\n",
      "to butterflies blood...\n",
      "a good a.m. from figures\n",
      "notice seeing night -- -\n",
      "with a buying man is his\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model):\n",
    "    # All sentences begin with START_SYMBOL.\n",
    "    new_sentence = [word_index[start_symbol]]\n",
    "    # And end with STOP_SYMBOL.\n",
    "    while not new_sentence[-1] == word_index[stop_symbol]:\n",
    "        next_word_prob = model.fwd_prop(new_sentence)\n",
    "        sampled_word = word_index[unknown_token]\n",
    "        # If unknown token, replace with another word.\n",
    "        while sampled_word == word_index[unknown_token]:\n",
    "            samples = np.random.multinomial(1, next_word_prob[-1])\n",
    "            sampled_word = np.argmax(samples)\n",
    "        new_sentence.append(sampled_word)\n",
    "    sentence = [word_list[x] for x in new_sentence[1:-1]]\n",
    "    return sentence\n",
    "\n",
    "num_sentences = 20\n",
    "min_length = 5\n",
    "\n",
    "for i in range(num_sentences):\n",
    "    sent = []\n",
    "    # Filter out sentences that are too small.\n",
    "    while len(sent) < min_length:\n",
    "        sent = generate_sentence(model)\n",
    "    print ' '.join(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The 'poem' above was generated after training the network during 10 epochs. Not very exiting so far, but not everybody produces a masterpiece on their first attempt. The example poems below were generated after running the model for 60 epochs, varying the min_length of the sentences, and iterating over the results. Since the training was performed on individual sentences, I've reordered the output to make it a bit more coherent. I also helped the algorithm by selecting titles for each of the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Father at Home\n",
    "\n",
    "*my world cold is a*  \n",
    "*scandal home with the bedroom*  \n",
    "*and dislike it pajamas,*  \n",
    "*and my father.*  \n",
    "\n",
    "*time to the machine*  \n",
    "*and the sunlight was still lovely*  \n",
    "*he got to me yard parking*  \n",
    "*these roominghouses the cents*  \n",
    "\n",
    "*my cable tank to a-piece*  \n",
    "*courtesy, razz, bets,*  \n",
    "*as grinned as their little fists hanging new of*  \n",
    "\n",
    "*is god pisses,*  \n",
    "*tell the bible, i showing brains*  \n",
    "*as i knew you*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Katherine\n",
    "\n",
    "*schoolgirl than a elevator motel*  \n",
    "*Katherine from the determined shot*  \n",
    "*she had the fuck in*\n",
    "\n",
    "*toward the girly, story panties yes*  \n",
    "*then i told my whore*  \n",
    "*that i know to when the boys*  \n",
    "*can't have a woman*\n",
    "\n",
    "*into little intelligence, the pill*  \n",
    "*into the signal by the lady monster*  \n",
    "*call the green copulating survival nuts toward him*  \n",
    "*not mouth, from another half,*  \n",
    "*down to the court, she said.*\n",
    "\n",
    "*later what out: depression from the worms*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's Better\n",
    "\n",
    "*Dostoevsky behind night to the sound*  \n",
    "*psychiatrists in Beethoven...*  \n",
    "*spiritually at the men are emergency*\n",
    "\n",
    "*they are not better like to see a gone*  \n",
    "*instead the poor from my wine.*\n",
    "\n",
    "*in any red wine*  \n",
    "*red killed odors as passed, world*  \n",
    "*his glass and muddy wino almost alive.*\n",
    "\n",
    "*flushes, I said, this ridiculous*  \n",
    "*if you drink rays the back bar*  \n",
    "*out the old men will come to me*  \n",
    "*wouldn't want her kiss*  \n",
    "*and i said, but there's better.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jailbirds, Monkeys, Women\n",
    "\n",
    "*readings in eyes when he felt all hard sauerkraut  \n",
    "wonderfully bothered break and I got to  \n",
    "the gas he says said into almost  \n",
    "there monkey-rhyme that I walked out of higher,  \n",
    "but jailbirds forced serve in my whore -- -  \n",
    "the change, he said, very tendency woman.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Unfortunately the output sentences are still not very coherent, and due to the way the model was trained, each of them holds no relationship with the prior one. To fully take advantage of the neural network capabilities we need a much larger training sample. Additionally we can enhance the model by implementing a LSTM network, as suggested by Denny on his tutorial on WildML. In any case this proved an interesting exercise, and I'm happy with the results as they do have a Bukowski-like feel, this considering we didn't provide any explicit grammatical information to the model at all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
